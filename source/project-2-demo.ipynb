{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\n\nif not os.path.exists('/kaggle/working/efficient-kan'):\n    !git clone https://github.com/Blealtan/efficient-kan\n\nif '/kaggle/working/efficient-kan/src' not in sys.path:\n    sys.path.append('/kaggle/working/efficient-kan/src')\n    \n!pip install gdown\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport copy\nimport gc\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer\n\nfrom efficient_kan import KANLinear\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# device = torch.device(\"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-02T16:42:29.701719Z","iopub.execute_input":"2024-09-02T16:42:29.702202Z","iopub.status.idle":"2024-09-02T16:42:42.606784Z","shell.execute_reply.started":"2024-09-02T16:42:29.702163Z","shell.execute_reply":"2024-09-02T16:42:42.605359Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.7.4)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/stopwords/vietnamese-stopwords\n    \nwith open('/kaggle/working/vietnamese-stopwords/vietnamese-stopwords.txt', 'r', encoding='utf-8') as file:\n    stop_words = file.read()\n    stop_words = stop_words.split('\\n')","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:42:42.609391Z","iopub.execute_input":"2024-09-02T16:42:42.609828Z","iopub.status.idle":"2024-09-02T16:42:43.697930Z","shell.execute_reply.started":"2024-09-02T16:42:42.609785Z","shell.execute_reply":"2024-09-02T16:42:43.696518Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"fatal: destination path 'vietnamese-stopwords' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"def remove_stopwords(text, stop_words):\n    words = text.split(' ')\n    \n    filtered_words = [word for word in words if word.lower() not in stop_words]\n    \n    return ' '.join(filtered_words)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:42:43.699752Z","iopub.execute_input":"2024-09-02T16:42:43.700203Z","iopub.status.idle":"2024-09-02T16:42:43.706807Z","shell.execute_reply.started":"2024-09-02T16:42:43.700158Z","shell.execute_reply":"2024-09-02T16:42:43.705588Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## Demo newspaper","metadata":{}},{"cell_type":"code","source":"content = '''\nSa Pa, Phan Thiết đông nghịt khách trong khi Đà Lạt, Vũng Tàu và nhiều điểm du lịch khác đông nhưng không xảy ra tình trạng chen chúc trong dịp lễ 2/9.\n\nNhư dự báo trước lễ, Sa Pa là điểm thu hút khách bậc nhất miền Bắc với công suất phòng 80-90%. Trong ngày 31/8 và 1/9, du khách di chuyển trong phố khó khăn vì đường nhỏ, lượng xe cá nhân đổ lên đông.\n\nTheo một số đơn vị tổ chức tour Sa Pa, ngày thường, xe chở khách chỉ mất khoảng 15 phút để di chuyển từ bãi xe trung tâm về khách sạn nhưng dịp này phải mất hơn 40 phút. Do nhiều tuyến đường cấm xe ôtô trong dịp lễ như đoạn đi bản Cát Cát, các đoàn khách phải di chuyển bằng xe điện tới gần đường vào bản, tiếp tục đi bộ rồi trung chuyển lên ôtô để đi tham quan. Một số khách thiếu kinh nghiệm, không đặt trước phòng phải quay xe về Lào Cai hoặc đến các bản lân cận lưu trú.\n\nKhu du lịch Fansipan Legend, nơi trang hoàng bằng hàng nghìn lá cờ đỏ sao vàng chào mừng Quốc khánh, ghi nhận lượng khách trong hai ngày đầu lễ tăng 45% so với cùng kỳ. Theo đại diện khu du lịch, nhiều doanh nghiệp, đơn vị đã chọn lên đỉnh Fansipan để du lịch và tham gia các hoạt động lan tỏa tình yêu nước. Một số đoàn phải đổi lịch trình tham quan Fansipan từ sáng sang chiều để tránh cảnh đông đúc.\n\nThời tiết miền Bắc dịp lễ nắng đẹp, mát mẻ, tạo điều kiện cho các đoàn du lịch. Minh Thắng, hướng dẫn viên du lịch cung Mộc Châu - Ninh Bình - Hà Nội nói các điểm tham quan không bị quá tải. Mộc Châu tắc đường nhẹ trong ngày 1/9 do tổ chức lễ hội. Tràng An, Ninh Bình đông khách hơn nhưng các đoàn cũng không phải chờ đợi lâu. Khu vực Phong Nha, Ninh Bình sáng 2/9 đón lượng khách không đông như năm ngoái.\n\nTrong hai ngày đầu nghỉ lễ Quốc khánh 2/9 (31/9 và 1/9), tổng khách du lịch đến các điểm tham quan, du lịch trên toàn tỉnh Quảng Ninh ước đạt 289.000 lượt, bằng 134% cùng kỳ năm 2023. Hạ Long thu hút khách nhất tỉnh với 67.700 lượt, tiếp đến là Móng Cái, Vân Đồn với 22.000 lượt khách.\n\nỞ miền Trung, Khu di tích Quốc gia đặc biệt Kim Liên, nằm trên địa bàn xã Kim Liên huyện Nam Đàn, tỉnh Nghệ An, dự kiến đón 3.000 đoàn khách và hàng chục nghìn lượt khách tới thăm dịp 2/9. Đây là quần thể di tích gắn liền với tuổi thơ Chủ tịch Hồ Chí Minh, cách thành phố Vinh 15 km.\n\n\"Nhiều năm nay, dịp Quốc khánh tôi luôn đưa các con đến Kim Liên tham quan để cháu hiểu rõ hơn về cuộc đời, sự nghiệp của Chủ tịch Hồ Chí Minh, từ đó nỗ lực, cố gắng đạt thành tích tốt trong năm học mới\", chị Thanh Thủy, 39 tuổi, đến từ huyện Thạch Hà, tỉnh Hà Tĩnh, nói. Ban quản lý khu cho biết di tích đã huy động tất cả cán bộ, nhân viên làm việc thông suốt kỳ nghỉ lễ để người dân, du khách khi về với quê Bác được phục vụ tốt nhất.\n\nTại Đà Nẵng và Hội An, hướng dẫn viên du lịch Huỳnh Trung nói các điểm du lịch không xảy ra cảnh chen chúc hay phải chờ đợi lâu. Tại khu du lịch Bà Nà Hills, khách lên xuống cáp treo không cần xếp hàng. Khách du lịch dịp này chủ yếu là người địa phương hoặc các vùng lân cận.\n\nNguyễn Tiến, hướng dẫn viên cung Di sản miền Trung của Du Lịch Việt, nói các điểm chùa Linh Ứng, bán đảo Sơn Trà, Ngũ Hành Sơn, Hội An, Bà Nà Hills, thánh địa La Vang trong hai ngày 1/9 và 2/9 không bị quá tải. Quãng đường từ Huế ra Phong Nha, Quảng Bình sáng 2/9 cũng thông thoáng.\n\nĐại diện Khu du lịch Bà Nà Hills dự kiến lượng khách trong bốn ngày lễ tăng 25% so với cùng kỳ năm trước. Khu du lịch đã triển khai nhiều hoạt động đón khách như trang trí cầu Vàng bằng hàng trăm lá cờ Tổ quốc, tạo hình nhiều món ăn lấy ý tưởng từ Quốc kỳ, miễn phí tham quan xưởng bia thủ công cho những du khách mặc áo cờ đỏ sao vàng.\n\nTại Nha Trang, thời tiết đẹp nhưng lượng khách không quá đông. Ghi nhận tại cảng tàu du lịch Nha Trang sáng 1/9, nhiều khách đợi tàu lâu nhưng sáng 2/9 không xảy ra tình trạng chen chúc. Hướng dẫn viên địa phương Nhã Phương nói đây là tình trạng chung dịp 2/9 vì khách đã dồn đi trong dịp hè. Dịp lễ này, nhiều resort, villa ở Cam Ranh hết phòng, chủ yếu khách từ địa phương lân cận đi xe cá nhân tới lưu trú.\n\nỞ Quy Nhơn và Phú Yên thời tiết nắng nóng, vắng khách, giao thông thuận tiện như ngày thường. Điểm nóng du lịch Kỳ Co - Eo Gió ở Quy Nhơn không đông trong sáng 2/9. Tại Tuy Hòa, thời tiết nóng nên khách không ra tắm biển vào buổi sáng, các điểm du lịch trong thành phố cũng chung tình trạng vắng vẻ.\n'''\nprint(len(content))","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:42:43.709753Z","iopub.execute_input":"2024-09-02T16:42:43.710205Z","iopub.status.idle":"2024-09-02T16:42:43.723018Z","shell.execute_reply.started":"2024-09-02T16:42:43.710161Z","shell.execute_reply":"2024-09-02T16:42:43.721806Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"4265\n","output_type":"stream"}]},{"cell_type":"code","source":"cleaned_content = remove_stopwords(content, stop_words)\nprint(len(cleaned_content))","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:42:43.724570Z","iopub.execute_input":"2024-09-02T16:42:43.725005Z","iopub.status.idle":"2024-09-02T16:42:43.762390Z","shell.execute_reply.started":"2024-09-02T16:42:43.724942Z","shell.execute_reply":"2024-09-02T16:42:43.761097Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"2839\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:42:43.764110Z","iopub.execute_input":"2024-09-02T16:42:43.764631Z","iopub.status.idle":"2024-09-02T16:42:44.498605Z","shell.execute_reply.started":"2024-09-02T16:42:43.764578Z","shell.execute_reply":"2024-09-02T16:42:44.497296Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"test_sequence = tokenizer([cleaned_content],\n                                    padding='max_length',\n                                    truncation=True,\n                                    max_length=8000,\n                                    return_tensors=\"pt\"\n                                )\nprint(test_sequence['input_ids'].shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:42:44.500094Z","iopub.execute_input":"2024-09-02T16:42:44.500481Z","iopub.status.idle":"2024-09-02T16:42:44.522595Z","shell.execute_reply.started":"2024-09-02T16:42:44.500442Z","shell.execute_reply":"2024-09-02T16:42:44.521463Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"torch.Size([1, 8000])\n","output_type":"stream"}]},{"cell_type":"code","source":"labels_dict = {\n    \"chính trị\": 1,\n    \"xã hội\": 2,\n    \"kinh tế\": 3,\n    \"văn hóa\": 4,\n    \"sức khỏe\": 5,\n    \"pháp luật\": 6,\n    \"thế giới\": 7,\n    \"khcn\": 8,\n    \"thể thao\": 9,\n    \"giải trí\": 10,\n    \"du lịch\": 11,\n    \"giáo dục\": 12\n}\n\nreverse_labels_dict = {v: k for k, v in labels_dict.items()}\nprint(reverse_labels_dict)\n\nnum_classes = 12","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:42:44.524227Z","iopub.execute_input":"2024-09-02T16:42:44.524651Z","iopub.status.idle":"2024-09-02T16:42:44.534254Z","shell.execute_reply.started":"2024-09-02T16:42:44.524604Z","shell.execute_reply":"2024-09-02T16:42:44.532779Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"{1: 'chính trị', 2: 'xã hội', 3: 'kinh tế', 4: 'văn hóa', 5: 'sức khỏe', 6: 'pháp luật', 7: 'thế giới', 8: 'khcn', 9: 'thể thao', 10: 'giải trí', 11: 'du lịch', 12: 'giáo dục'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Define models and load weights","metadata":{}},{"cell_type":"code","source":"!gdown --folder https://drive.google.com/drive/folders/1iG4ubXgej2_KMAsrdIB8CpdGypKTJTrf","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:42:44.535941Z","iopub.execute_input":"2024-09-02T16:42:44.536453Z","iopub.status.idle":"2024-09-02T16:43:09.219607Z","shell.execute_reply.started":"2024-09-02T16:42:44.536412Z","shell.execute_reply":"2024-09-02T16:43:09.217699Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Retrieving folder contents\nProcessing file 12Q72qowIDOycscGrPEcCv6cgTkXQi7Qq 1d_cnn_best_loss_weigth.pth\nProcessing file 1NS8GCH_xGUY6YDjZel9c1IN83q4SqHFo bi_gru_best_loss_weigth.pth\nProcessing file 1gRO5HeiI-kTItd7uBZYleGd9-gsm5u22 bi_lstm_best_loss_weigth.pth\nProcessing file 1J-KVSRvwOrbaXQAHM9IwAKgHhR3eSTOl minibert_best_loss_weigth.pth\nRetrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom: https://drive.google.com/uc?id=12Q72qowIDOycscGrPEcCv6cgTkXQi7Qq\nTo: /kaggle/working/weights/1d_cnn_best_loss_weigth.pth\n100%|██████████████████████████████████████| 24.8M/24.8M [00:01<00:00, 16.5MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1NS8GCH_xGUY6YDjZel9c1IN83q4SqHFo\nTo: /kaggle/working/weights/bi_gru_best_loss_weigth.pth\n100%|███████████████████████████████████████| 11.0M/11.0M [00:00<00:00, 102MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1gRO5HeiI-kTItd7uBZYleGd9-gsm5u22\nTo: /kaggle/working/weights/bi_lstm_best_loss_weigth.pth\n100%|██████████████████████████████████████| 11.2M/11.2M [00:00<00:00, 19.3MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1J-KVSRvwOrbaXQAHM9IwAKgHhR3eSTOl\nTo: /kaggle/working/weights/minibert_best_loss_weigth.pth\n100%|██████████████████████████████████████| 12.7M/12.7M [00:00<00:00, 14.9MB/s]\nDownload completed\n","output_type":"stream"}]},{"cell_type":"code","source":"class Block1(nn.Module):\n    def __init__(self, in_channel, out_channel, seq_len):\n        super().__init__()\n        self.backbone = nn.Sequential(\n            nn.Conv1d(in_channel, out_channel, 5, stride=1, dilation=2, padding=4),\n            nn.LayerNorm([out_channel, seq_len]),\n            nn.SiLU(),\n            nn.Dropout(0.5)\n        )\n        \n    def forward(self, x):\n        return self.backbone(x)\n\n# 1D CNN\nclass Model1(nn.Module):\n    def __init__(self):\n        super().__init__()\n        st = 32\n        \n        self.input_embedding = nn.Embedding(64000, st)\n        \n        self.backbone = nn.Sequential(\n            Block1(st, 2*st, 8000),\n            nn.AvgPool1d(2),\n            Block1(2*st, 4*st, 4000),\n            nn.AvgPool1d(2),\n            Block1(4*st, 8*st, 2000),\n            nn.AvgPool1d(2),\n            Block1(8*st, 8*st, 1000),\n            nn.AdaptiveAvgPool1d(1)\n        )\n        \n        self.classifier = KANLinear(8*st, num_classes)\n        \n    def forward(self, x):\n        x = self.input_embedding(x)\n        if (x.shape[0] != 1):\n            x = x.squeeze()\n        x = x.transpose(1, 2)\n        x = self.backbone(x).squeeze()\n        x = self.classifier(x)\n        return x\n\nmodel1 = Model1().to(device)\nmodel1.load_state_dict(torch.load('/kaggle/working/weights/1d_cnn_best_loss_weigth.pth', map_location=device))\nmodel1.eval()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:43:09.224025Z","iopub.execute_input":"2024-09-02T16:43:09.224464Z","iopub.status.idle":"2024-09-02T16:43:09.307749Z","shell.execute_reply.started":"2024-09-02T16:43:09.224416Z","shell.execute_reply":"2024-09-02T16:43:09.306348Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/973584290.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model1.load_state_dict(torch.load('/kaggle/working/weights/1d_cnn_best_loss_weigth.pth', map_location=device))\n","output_type":"stream"},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"Model1(\n  (input_embedding): Embedding(64000, 32)\n  (backbone): Sequential(\n    (0): Block1(\n      (backbone): Sequential(\n        (0): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(4,), dilation=(2,))\n        (1): LayerNorm((64, 8000), eps=1e-05, elementwise_affine=True)\n        (2): SiLU()\n        (3): Dropout(p=0.5, inplace=False)\n      )\n    )\n    (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n    (2): Block1(\n      (backbone): Sequential(\n        (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(4,), dilation=(2,))\n        (1): LayerNorm((128, 4000), eps=1e-05, elementwise_affine=True)\n        (2): SiLU()\n        (3): Dropout(p=0.5, inplace=False)\n      )\n    )\n    (3): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n    (4): Block1(\n      (backbone): Sequential(\n        (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(4,), dilation=(2,))\n        (1): LayerNorm((256, 2000), eps=1e-05, elementwise_affine=True)\n        (2): SiLU()\n        (3): Dropout(p=0.5, inplace=False)\n      )\n    )\n    (5): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n    (6): Block1(\n      (backbone): Sequential(\n        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(4,), dilation=(2,))\n        (1): LayerNorm((256, 1000), eps=1e-05, elementwise_affine=True)\n        (2): SiLU()\n        (3): Dropout(p=0.5, inplace=False)\n      )\n    )\n    (7): AdaptiveAvgPool1d(output_size=1)\n  )\n  (classifier): KANLinear(\n    (base_activation): SiLU()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Bi-LSTM\nclass Model2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        st = 32\n        \n        self.input_embedding = nn.Embedding(64000, st)\n        \n        # Reduce sequence length from 8000 to 1000\n        self.conv = nn.Sequential(\n            nn.Conv1d(st, st*2, 5, stride=2, padding=2),\n            nn.LayerNorm([st*2, 4000]),\n            nn.SiLU(),\n            nn.AvgPool1d(8, stride=4, padding=2),\n            nn.Dropout(0.5)\n        )\n        \n        self.hidden_size = st*4\n        self.num_layers = 1\n        self.backbone = nn.LSTM(st*2, self.hidden_size, num_layers=self.num_layers, batch_first=True, bidirectional=True)\n        \n        self.classifier = KANLinear(self.hidden_size*2, num_classes)\n        \n    def forward(self, x):        \n        x = self.input_embedding(x)\n        if (x.shape[0] != 1):\n            x = x.squeeze()\n        \n        x = x.transpose(1, 2)\n        x = self.conv(x)\n        x = x.transpose(1, 2)\n        \n        h0 = torch.zeros(2*self.num_layers, x.size(0), self.hidden_size).to(x.device)\n        c0 = torch.zeros(2*self.num_layers, x.size(0), self.hidden_size).to(x.device)\n        \n        output, _ = self.backbone(x, (h0, c0))\n            \n        output = self.classifier(output[:, -1, :])\n        return output\n    \nmodel2 = Model2().to(device)\nmodel2.load_state_dict(torch.load('/kaggle/working/weights/bi_lstm_best_loss_weigth.pth', map_location=device))\nmodel2.eval()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:43:09.309776Z","iopub.execute_input":"2024-09-02T16:43:09.310914Z","iopub.status.idle":"2024-09-02T16:43:09.363853Z","shell.execute_reply.started":"2024-09-02T16:43:09.310850Z","shell.execute_reply":"2024-09-02T16:43:09.362197Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1719540135.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model2.load_state_dict(torch.load('/kaggle/working/weights/bi_lstm_best_loss_weigth.pth', map_location=device))\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"Model2(\n  (input_embedding): Embedding(64000, 32)\n  (conv): Sequential(\n    (0): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(2,))\n    (1): LayerNorm((64, 4000), eps=1e-05, elementwise_affine=True)\n    (2): SiLU()\n    (3): AvgPool1d(kernel_size=(8,), stride=(4,), padding=(2,))\n    (4): Dropout(p=0.5, inplace=False)\n  )\n  (backbone): LSTM(64, 128, batch_first=True, bidirectional=True)\n  (classifier): KANLinear(\n    (base_activation): SiLU()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Bi-GRU\nclass Model3(nn.Module):\n    def __init__(self):\n        super().__init__()\n        st = 32\n        \n        self.input_embedding = nn.Embedding(64000, st)\n        \n        # Reduce sequence length from 8000 to 1000\n        self.conv = nn.Sequential(\n            nn.Conv1d(st, st*2, 5, stride=2, padding=2),\n            nn.LayerNorm([st*2, 4000]),\n            nn.SiLU(),\n            nn.AvgPool1d(8, stride=4, padding=2),\n            nn.Dropout(0.5)\n        )\n        \n        self.hidden_size = st*4\n        self.num_layers = 1\n        self.backbone = nn.GRU(st*2, self.hidden_size, num_layers=self.num_layers, batch_first=True, bidirectional=True)\n        \n        self.classifier = KANLinear(self.hidden_size*2, num_classes)\n        \n    def forward(self, x):        \n        x = self.input_embedding(x)\n        if (x.shape[0] != 1):\n            x = x.squeeze()\n        \n        x = x.transpose(1, 2)\n        x = self.conv(x)\n        x = x.transpose(1, 2)\n        \n        h0 = torch.zeros(2*self.num_layers, x.size(0), self.hidden_size).to(x.device)\n        \n        output, _ = self.backbone(x, h0)\n            \n        output = self.classifier(output[:, -1, :])\n        return output\n    \nmodel3 = Model3().to(device)\nmodel3.load_state_dict(torch.load('/kaggle/working/weights/bi_gru_best_loss_weigth.pth', map_location=device))\nmodel3.eval()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:43:09.365901Z","iopub.execute_input":"2024-09-02T16:43:09.366429Z","iopub.status.idle":"2024-09-02T16:43:09.429281Z","shell.execute_reply.started":"2024-09-02T16:43:09.366376Z","shell.execute_reply":"2024-09-02T16:43:09.427888Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1390676918.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model3.load_state_dict(torch.load('/kaggle/working/weights/bi_gru_best_loss_weigth.pth', map_location=device))\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"Model3(\n  (input_embedding): Embedding(64000, 32)\n  (conv): Sequential(\n    (0): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(2,))\n    (1): LayerNorm((64, 4000), eps=1e-05, elementwise_affine=True)\n    (2): SiLU()\n    (3): AvgPool1d(kernel_size=(8,), stride=(4,), padding=(2,))\n    (4): Dropout(p=0.5, inplace=False)\n  )\n  (backbone): GRU(64, 128, batch_first=True, bidirectional=True)\n  (classifier): KANLinear(\n    (base_activation): SiLU()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Kernel function\nclass Phi(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, x):\n        return F.elu(x) + 1\n\nclass AttentionLayer(nn.Module): # Linear Attention using Kernel\n    def __init__(self, d_model=512, num_heads=8):\n        super().__init__()\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.head_dim = d_model // num_heads\n\n        self.W_query = nn.Linear(d_model, d_model)\n        self.W_key = nn.Linear(d_model, d_model)\n        self.W_value = nn.Linear(d_model, d_model)\n        \n        self.phi = Phi()\n        \n        self.out_proj = KANLinear(d_model, d_model)\n\n    def forward(self, x):\n        bs, seq_len, d_model = x.shape\n\n        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n        queries = self.W_query(x)\n        values = self.W_value(x)\n\n        # Unroll last dim: (bs, seq_len, d_model) -> (bs, num_tokens, seq_len, num_head, head_dim)\n        keys = keys.view(bs, seq_len, self.num_heads, self.head_dim)\n        values = values.view(bs, seq_len, self.num_heads, self.head_dim)\n        queries = queries.view(bs, seq_len, self.num_heads, self.head_dim)\n\n        # Transpose: (bs, seq_len, num_heads, head_dim) -> (bs, num_heads, seq_len, head_dim)\n        keys = keys.transpose(1, 2)\n        queries = queries.transpose(1, 2)\n        values = values.transpose(1, 2)\n\n        attn_weights = self.phi(keys.transpose(-1, -2)) @ values\n        attn_weights = self.phi(queries) @ attn_weights\n\n        # Combine heads, where self.d_model = self.num_heads * self.head_dim\n        attn_weights = attn_weights.reshape(bs, seq_len, self.d_model)\n        out = self.out_proj(attn_weights)\n\n        return out\n    \nclass EncoderLayer(nn.Module): # Pre-layernorm\n    def __init__(self, d_model=512, num_heads=8, dropout=0.2):\n        super().__init__()\n        \n        self.attention = AttentionLayer(d_model, num_heads)\n        self.ff = KANLinear(d_model, d_model)\n        self.ln1 = nn.LayerNorm(d_model)\n        self.ln2 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        tmp = self.ln1(x)\n        tmp = self.attention(tmp)\n        tmp = self.dropout(tmp)\n        x = x + tmp\n        \n        tmp = self.ln2(x)\n        tmp = self.ff(tmp)\n        tmp = self.dropout(tmp)\n        x = x + tmp\n        return x\n    \n# MiniBERT\nclass Model4(nn.Module):\n    def __init__(self):\n        super().__init__()\n        st = 32\n        \n        self.input_embedding = nn.Embedding(64000, st)\n        \n        # Reduce sequence length from 8000 to 1000\n        self.conv = nn.Sequential(\n            nn.Conv1d(st, st*2, 5, stride=2, padding=2),\n            nn.LayerNorm([st*2, 4000]),\n            nn.SiLU(),\n            nn.AvgPool1d(8, stride=4, padding=2)\n        )\n        \n        self.upsampling = nn.Sequential(\n            KANLinear(st*2, st*4),\n            nn.Dropout(0.4)\n        )\n        \n        self.pos_emb = nn.Embedding(1000, st*4)\n        position = torch.arange(0, 1000).unsqueeze(0)\n        self.register_buffer('position', position)\n        \n        self.backbone = EncoderLayer(d_model=st*4, num_heads=4, dropout=0.4)\n        self.lastnorm = nn.LayerNorm(st*4)\n        \n        self.classifier = KANLinear(st*4, num_classes)\n        \n    def forward(self, x):        \n        x = self.input_embedding(x)\n        if (x.shape[0] != 1):\n            x = x.squeeze()\n        \n        x = x.transpose(1, 2)\n        x = self.conv(x)\n        x = x.transpose(1, 2)\n        x = self.upsampling(x)\n        \n        x = x + self.pos_emb(self.position)\n        \n        output = self.backbone(x)\n        output = self.lastnorm(output)\n            \n        output = self.classifier(output[:, 0, :])\n        return output\n    \nmodel4 = Model4().to(device)\nmodel4.load_state_dict(torch.load('/kaggle/working/weights/minibert_best_loss_weigth.pth', map_location=device))\nmodel4.eval()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:43:09.431567Z","iopub.execute_input":"2024-09-02T16:43:09.432078Z","iopub.status.idle":"2024-09-02T16:43:09.538941Z","shell.execute_reply.started":"2024-09-02T16:43:09.432023Z","shell.execute_reply":"2024-09-02T16:43:09.537509Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3495480299.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model4.load_state_dict(torch.load('/kaggle/working/weights/minibert_best_loss_weigth.pth', map_location=device))\n","output_type":"stream"},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"Model4(\n  (input_embedding): Embedding(64000, 32)\n  (conv): Sequential(\n    (0): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(2,))\n    (1): LayerNorm((64, 4000), eps=1e-05, elementwise_affine=True)\n    (2): SiLU()\n    (3): AvgPool1d(kernel_size=(8,), stride=(4,), padding=(2,))\n  )\n  (upsampling): Sequential(\n    (0): KANLinear(\n      (base_activation): SiLU()\n    )\n    (1): Dropout(p=0.4, inplace=False)\n  )\n  (pos_emb): Embedding(1000, 128)\n  (backbone): EncoderLayer(\n    (attention): AttentionLayer(\n      (W_query): Linear(in_features=128, out_features=128, bias=True)\n      (W_key): Linear(in_features=128, out_features=128, bias=True)\n      (W_value): Linear(in_features=128, out_features=128, bias=True)\n      (phi): Phi()\n      (out_proj): KANLinear(\n        (base_activation): SiLU()\n      )\n    )\n    (ff): KANLinear(\n      (base_activation): SiLU()\n    )\n    (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n    (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.4, inplace=False)\n  )\n  (lastnorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n  (classifier): KANLinear(\n    (base_activation): SiLU()\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"print(content)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:43:09.540538Z","iopub.execute_input":"2024-09-02T16:43:09.540935Z","iopub.status.idle":"2024-09-02T16:43:09.546809Z","shell.execute_reply.started":"2024-09-02T16:43:09.540892Z","shell.execute_reply":"2024-09-02T16:43:09.545754Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"\nSa Pa, Phan Thiết đông nghịt khách trong khi Đà Lạt, Vũng Tàu và nhiều điểm du lịch khác đông nhưng không xảy ra tình trạng chen chúc trong dịp lễ 2/9.\n\nNhư dự báo trước lễ, Sa Pa là điểm thu hút khách bậc nhất miền Bắc với công suất phòng 80-90%. Trong ngày 31/8 và 1/9, du khách di chuyển trong phố khó khăn vì đường nhỏ, lượng xe cá nhân đổ lên đông.\n\nTheo một số đơn vị tổ chức tour Sa Pa, ngày thường, xe chở khách chỉ mất khoảng 15 phút để di chuyển từ bãi xe trung tâm về khách sạn nhưng dịp này phải mất hơn 40 phút. Do nhiều tuyến đường cấm xe ôtô trong dịp lễ như đoạn đi bản Cát Cát, các đoàn khách phải di chuyển bằng xe điện tới gần đường vào bản, tiếp tục đi bộ rồi trung chuyển lên ôtô để đi tham quan. Một số khách thiếu kinh nghiệm, không đặt trước phòng phải quay xe về Lào Cai hoặc đến các bản lân cận lưu trú.\n\nKhu du lịch Fansipan Legend, nơi trang hoàng bằng hàng nghìn lá cờ đỏ sao vàng chào mừng Quốc khánh, ghi nhận lượng khách trong hai ngày đầu lễ tăng 45% so với cùng kỳ. Theo đại diện khu du lịch, nhiều doanh nghiệp, đơn vị đã chọn lên đỉnh Fansipan để du lịch và tham gia các hoạt động lan tỏa tình yêu nước. Một số đoàn phải đổi lịch trình tham quan Fansipan từ sáng sang chiều để tránh cảnh đông đúc.\n\nThời tiết miền Bắc dịp lễ nắng đẹp, mát mẻ, tạo điều kiện cho các đoàn du lịch. Minh Thắng, hướng dẫn viên du lịch cung Mộc Châu - Ninh Bình - Hà Nội nói các điểm tham quan không bị quá tải. Mộc Châu tắc đường nhẹ trong ngày 1/9 do tổ chức lễ hội. Tràng An, Ninh Bình đông khách hơn nhưng các đoàn cũng không phải chờ đợi lâu. Khu vực Phong Nha, Ninh Bình sáng 2/9 đón lượng khách không đông như năm ngoái.\n\nTrong hai ngày đầu nghỉ lễ Quốc khánh 2/9 (31/9 và 1/9), tổng khách du lịch đến các điểm tham quan, du lịch trên toàn tỉnh Quảng Ninh ước đạt 289.000 lượt, bằng 134% cùng kỳ năm 2023. Hạ Long thu hút khách nhất tỉnh với 67.700 lượt, tiếp đến là Móng Cái, Vân Đồn với 22.000 lượt khách.\n\nỞ miền Trung, Khu di tích Quốc gia đặc biệt Kim Liên, nằm trên địa bàn xã Kim Liên huyện Nam Đàn, tỉnh Nghệ An, dự kiến đón 3.000 đoàn khách và hàng chục nghìn lượt khách tới thăm dịp 2/9. Đây là quần thể di tích gắn liền với tuổi thơ Chủ tịch Hồ Chí Minh, cách thành phố Vinh 15 km.\n\n\"Nhiều năm nay, dịp Quốc khánh tôi luôn đưa các con đến Kim Liên tham quan để cháu hiểu rõ hơn về cuộc đời, sự nghiệp của Chủ tịch Hồ Chí Minh, từ đó nỗ lực, cố gắng đạt thành tích tốt trong năm học mới\", chị Thanh Thủy, 39 tuổi, đến từ huyện Thạch Hà, tỉnh Hà Tĩnh, nói. Ban quản lý khu cho biết di tích đã huy động tất cả cán bộ, nhân viên làm việc thông suốt kỳ nghỉ lễ để người dân, du khách khi về với quê Bác được phục vụ tốt nhất.\n\nTại Đà Nẵng và Hội An, hướng dẫn viên du lịch Huỳnh Trung nói các điểm du lịch không xảy ra cảnh chen chúc hay phải chờ đợi lâu. Tại khu du lịch Bà Nà Hills, khách lên xuống cáp treo không cần xếp hàng. Khách du lịch dịp này chủ yếu là người địa phương hoặc các vùng lân cận.\n\nNguyễn Tiến, hướng dẫn viên cung Di sản miền Trung của Du Lịch Việt, nói các điểm chùa Linh Ứng, bán đảo Sơn Trà, Ngũ Hành Sơn, Hội An, Bà Nà Hills, thánh địa La Vang trong hai ngày 1/9 và 2/9 không bị quá tải. Quãng đường từ Huế ra Phong Nha, Quảng Bình sáng 2/9 cũng thông thoáng.\n\nĐại diện Khu du lịch Bà Nà Hills dự kiến lượng khách trong bốn ngày lễ tăng 25% so với cùng kỳ năm trước. Khu du lịch đã triển khai nhiều hoạt động đón khách như trang trí cầu Vàng bằng hàng trăm lá cờ Tổ quốc, tạo hình nhiều món ăn lấy ý tưởng từ Quốc kỳ, miễn phí tham quan xưởng bia thủ công cho những du khách mặc áo cờ đỏ sao vàng.\n\nTại Nha Trang, thời tiết đẹp nhưng lượng khách không quá đông. Ghi nhận tại cảng tàu du lịch Nha Trang sáng 1/9, nhiều khách đợi tàu lâu nhưng sáng 2/9 không xảy ra tình trạng chen chúc. Hướng dẫn viên địa phương Nhã Phương nói đây là tình trạng chung dịp 2/9 vì khách đã dồn đi trong dịp hè. Dịp lễ này, nhiều resort, villa ở Cam Ranh hết phòng, chủ yếu khách từ địa phương lân cận đi xe cá nhân tới lưu trú.\n\nỞ Quy Nhơn và Phú Yên thời tiết nắng nóng, vắng khách, giao thông thuận tiện như ngày thường. Điểm nóng du lịch Kỳ Co - Eo Gió ở Quy Nhơn không đông trong sáng 2/9. Tại Tuy Hòa, thời tiết nóng nên khách không ra tắm biển vào buổi sáng, các điểm du lịch trong thành phố cũng chung tình trạng vắng vẻ.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = model1(test_sequence['input_ids'])\ny_pred = torch.argmax(y_pred) + 1\ny_pred = reverse_labels_dict[y_pred.item()]\nprint(y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:43:09.548065Z","iopub.execute_input":"2024-09-02T16:43:09.548442Z","iopub.status.idle":"2024-09-02T16:43:09.615954Z","shell.execute_reply.started":"2024-09-02T16:43:09.548388Z","shell.execute_reply":"2024-09-02T16:43:09.614696Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"du lịch\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = model2(test_sequence['input_ids'])\ny_pred = torch.argmax(y_pred) + 1\ny_pred = reverse_labels_dict[y_pred.item()]\nprint(y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:43:09.617492Z","iopub.execute_input":"2024-09-02T16:43:09.617951Z","iopub.status.idle":"2024-09-02T16:43:09.686522Z","shell.execute_reply.started":"2024-09-02T16:43:09.617899Z","shell.execute_reply":"2024-09-02T16:43:09.685433Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"xã hội\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = model3(test_sequence['input_ids'])\ny_pred = torch.argmax(y_pred) + 1\ny_pred = reverse_labels_dict[y_pred.item()]\nprint(y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:43:09.687786Z","iopub.execute_input":"2024-09-02T16:43:09.688150Z","iopub.status.idle":"2024-09-02T16:43:09.885346Z","shell.execute_reply.started":"2024-09-02T16:43:09.688112Z","shell.execute_reply":"2024-09-02T16:43:09.884038Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"du lịch\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = model4(test_sequence['input_ids'])\ny_pred = torch.argmax(y_pred) + 1\ny_pred = reverse_labels_dict[y_pred.item()]\nprint(y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T16:43:09.886854Z","iopub.execute_input":"2024-09-02T16:43:09.887283Z","iopub.status.idle":"2024-09-02T16:43:10.003844Z","shell.execute_reply.started":"2024-09-02T16:43:09.887244Z","shell.execute_reply":"2024-09-02T16:43:10.002588Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"du lịch\n","output_type":"stream"}]}]}